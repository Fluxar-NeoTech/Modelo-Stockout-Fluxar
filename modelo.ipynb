{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fbc6117",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; font-size:2.5em; color:#4B0055; letter-spacing:2px; background-color:#F5F5F5; padding:20px; border-radius:10px;\">\n",
    "    Modelo e An√°lise Explorat√≥ria de Dados: \n",
    "    <span style=\"color:#FFA726; font-weight:bold;\">Fluxar</span>\n",
    "    <div style=\"text-align:center; margin-top:10px;\">\n",
    "        <img src=\"logo_fluxar.png\" alt=\"Logo Fluxar\" style=\"height:70px;\">\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7610a9",
   "metadata": {},
   "source": [
    "<div style=\"background:#F7F3FF; border-left:8px solid #4B0055; padding:16px; margin-top:20px;\">\n",
    "    <span style=\"font-size:1.3em; color:#4B0055; font-weight:bold;\">Modelo escolhido:</span><br>\n",
    "    <span style=\"color:#FFA726; font-size:1.1em;\">Forecasting & Stockout Prediction ‚Äî <b>Fluxar</b></span>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd54b6ba",
   "metadata": {},
   "source": [
    "<div style=\"background:linear-gradient(90deg, #ffc164ff 0%, #FF1493 100%); color:white; padding:18px; border-radius:10px; margin-top:20px;\">\n",
    "    <span style=\"font-size:1.2em; font-weight:bold;\">Objetivos Concretos do Modelo do Fluxar:</span>\n",
    "    <ul style=\"margin-top:10px;\">\n",
    "        <li>Prever o n√∫mero de dias at√© o estoque acabar (<i>days_to_stockout</i>) para cada SKU, com janela de previs√£o de 14 dias.</li>\n",
    "        <li>Assim, o gestor consegue se antecipar antes que o produto falte.</li>\n",
    "        <li>Reduzir a ocorr√™ncia de <b>stockouts</b> em pelo menos <span>20%</span> (meta inicial), evitando perdas de vendas e desperd√≠cio log√≠stico.</li>\n",
    "        <li>Gerar alertas autom√°ticos no app (push notification ou no painel web) quando o estoque projetado cair abaixo de um limite cr√≠tico.</li>\n",
    "        <li>Fornecer insights de tend√™ncia (Exemplo: quais SKUs mais frequentemente entram em risco de stockout).</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ef0614",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4B0055; font-family:'Segoe UI', 'Arial', sans-serif;\">Importa√ß√£o de Bibliotecas</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cbe03711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para os pip install:\n",
    "# !pip install xgboost lightgbm catboost pandas numpy scikit-learn joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "34216cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para o dataset \n",
    "import os\n",
    "import shutil\n",
    "import kagglehub\n",
    "\n",
    "# Para an√°lise\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Para modelagem\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "\n",
    "# Para modelos\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Para treinamento dos modelos\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28126e4",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4B0055; font-family:'Segoe UI', 'Arial', sans-serif;\">Constru√ß√£o de pipeline de cria√ß√£o de ML </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcba04bf",
   "metadata": {},
   "source": [
    "<!-- Etapa 1 -->\n",
    "<div style=\"background:#F7F3FF; border-left:8px solid #FFA726; padding:18px; border-radius:10px; margin-top:24px;\">\n",
    "  <span style=\"font-size:1.2em; color:#4B0055; font-weight:bold;\">1. Defini√ß√£o do Problema</span>\n",
    "  <p style=\"color:#4B0055;\">\n",
    "    Objetivo: prever o n√∫mero de dias at√© o estoque acabar (<em>days_to_stockout</em>) para cada SKU/loja, com janela de previs√£o de 14 dias.<br>\n",
    "    Tipo de problema: regress√£o, pois a sa√≠da √© uma vari√°vel cont√≠nua.<br>\n",
    "    Metas concretas: reduzir stockouts, gerar alertas autom√°ticos, antecipar reposi√ß√£o.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6235eeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etapa 1 conclu√≠da: Problema definido\n"
     ]
    }
   ],
   "source": [
    "print(\"Etapa 1 conclu√≠da: Problema definido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee80726c",
   "metadata": {},
   "source": [
    "<!-- Etapa 2 -->\n",
    "<div style=\"background:#F7F3FF; border-left:8px solid #FFA726; padding:18px; border-radius:10px; margin-top:24px;\">\n",
    "  <span style=\"font-size:1.2em; color:#4B0055; font-weight:bold;\">2. Coleta de Dados</span>\n",
    "  <p style=\"color:#4B0055;\">\n",
    "    Dataset: <em>Retail Store Inventory Forecasting</em> (Kaggle)<br>\n",
    "    Inclui dados hist√≥ricos di√°rios de estoque, vendas, promo√ß√µes, feriados, clima, pre√ßos e categorias de produto.<br>\n",
    "    Objetivo: garantir hist√≥rico suficiente por SKU e loja para treinar modelos robustos.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2404a8cf",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4B0055; font-family:'Segoe UI', 'Arial', sans-serif;\">Carregar dados </span>\n",
    "Dataset proveniente do Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "81b71b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n",
      "‚úÖ | Dataset baixado em: C:\\Users\\mayumishimizu-ieg\\.cache\\kagglehub\\datasets\\anirudhchauhan\\retail-store-inventory-forecasting-dataset\\versions\\1\n",
      "üìÇ | Arquivo salvo e renomeado como: C:\\Users\\mayumishimizu-ieg\\OneDrive - Instituto Germinare\\√Årea de Trabalho\\2¬∫ ANO\\Interdisciplinar\\Matem√°tica Aplicada\\dataset_fluxar\\dataset_modelo.csv\n",
      "\n",
      "üîé | dataset_modelo.csv carregado com sucesso!\n",
      "Dimens√£o: (73100, 15)\n",
      "         Date Store ID Product ID     Category Region  Inventory Level  \\\n",
      "0  2022-01-01     S001      P0001    Groceries  North              231   \n",
      "1  2022-01-01     S001      P0002         Toys  South              204   \n",
      "2  2022-01-01     S001      P0003         Toys   West              102   \n",
      "3  2022-01-01     S001      P0004         Toys  North              469   \n",
      "4  2022-01-01     S001      P0005  Electronics   East              166   \n",
      "\n",
      "   Units Sold  Units Ordered  Demand Forecast  Price  Discount  \\\n",
      "0         127             55           135.47  33.50        20   \n",
      "1         150             66           144.04  63.01        20   \n",
      "2          65             51            74.02  27.99        10   \n",
      "3          61            164            62.18  32.72        10   \n",
      "4          14            135             9.26  73.64         0   \n",
      "\n",
      "  Weather Condition  Holiday/Promotion  Competitor Pricing Seasonality  \n",
      "0             Rainy                  0               29.69      Autumn  \n",
      "1             Sunny                  0               66.16      Autumn  \n",
      "2             Sunny                  1               31.32      Summer  \n",
      "3            Cloudy                  1               34.74      Autumn  \n",
      "4             Sunny                  0               68.95      Summer  \n"
     ]
    }
   ],
   "source": [
    "# Caminho final desejado\n",
    "destino = r\"C:\\Users\\mayumishimizu-ieg\\OneDrive - Instituto Germinare\\√Årea de Trabalho\\2¬∫ ANO\\Interdisciplinar\\Matem√°tica Aplicada\"\n",
    "destino_dataset = os.path.join(destino, \"dataset_fluxar\")\n",
    "os.makedirs(destino_dataset, exist_ok=True)\n",
    "\n",
    "# Baixar dataset do Kaggle\n",
    "try:\n",
    "    path = kagglehub.dataset_download(\"anirudhchauhan/retail-store-inventory-forecasting-dataset\")\n",
    "    print(\"‚úÖ | Dataset baixado em:\", path)\n",
    "except Exception as e:\n",
    "    print(\"‚ùå | Erro ao baixar dataset:\", e)\n",
    "\n",
    "# Copiar e renomear o primeiro CSV encontrado para \"dataset_modelo.csv\"\n",
    "for file in os.listdir(path):\n",
    "    full_file_path = os.path.join(path, file)\n",
    "    if os.path.isfile(full_file_path) and file.endswith(\".csv\"):\n",
    "        destino_final = os.path.join(destino_dataset, \"dataset_modelo.csv\")\n",
    "        shutil.copy(full_file_path, destino_final)\n",
    "        print(f\"üìÇ | Arquivo salvo e renomeado como: {destino_final}\")\n",
    "        break  # garante que s√≥ salva o primeiro CSV\n",
    "\n",
    "# Verifica√ß√£o r√°pida\n",
    "df = pd.read_csv(os.path.join(destino_dataset, \"dataset_modelo.csv\"))\n",
    "print(f\"\\nüîé | dataset_modelo.csv carregado com sucesso!\")\n",
    "print(f\"Dimens√£o: {df.shape}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5963ff",
   "metadata": {},
   "source": [
    "<!-- Etapa 3 -->\n",
    "<div style=\"background:#F7F3FF; border-left:8px solid #FFA726; padding:18px; border-radius:10px; margin-top:24px;\">\n",
    "  <span style=\"font-size:1.2em; color:#4B0055; font-weight:bold;\">3. Pr√©-processamento de Dados</span>\n",
    "  <ul style=\"color:#4B0055; margin-top:12px;\">\n",
    "    <li>Padronizar nomes de colunas: <code>Inventory Level ‚Üí Inventory_Level</code></li>\n",
    "    <li>Tratar valores ausentes e duplicados</li>\n",
    "    <li>Criar vari√°vel alvo: <code>days_to_stockout = Inventory_Level / (Units_Sold + 1e-5)</code></li>\n",
    "    <li>Criar features temporais: dia da semana, m√™s, fim de semana, feriado</li>\n",
    "    <li>Transformar vari√°veis categ√≥ricas em num√©ricas (Label Encoding ou One-Hot)</li>\n",
    "    <li>Remover outliers e dividir dados em treino/teste</li>\n",
    "  </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d8a4e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pr√©-processamento conclu√≠do. Shape final: (70701, 50)\n"
     ]
    }
   ],
   "source": [
    "# Carregar dataset\n",
    "caminho = r\"C:\\Users\\mayumishimizu-ieg\\OneDrive - Instituto Germinare\\√Årea de Trabalho\\2¬∫ ANO\\Interdisciplinar\\Matem√°tica Aplicada\\dataset_fluxar\\dataset_modelo.csv\"\n",
    "df = pd.read_csv(caminho)\n",
    "\n",
    "# Padronizar nomes de colunas\n",
    "df = df.rename(columns=lambda x: x.strip().replace(\" \", \"_\").replace(\"/\", \"_\"))\n",
    "\n",
    "# Converter datas\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "df = df.dropna(subset=['Date'])  # remove linhas com datas inv√°lidas\n",
    "\n",
    "# Ordenar dados\n",
    "df = df.sort_values(by=[\"Product_ID\", \"Store_ID\", \"Date\"])\n",
    "\n",
    "# Criar vari√°vel alvo com m√©dia m√≥vel de 7 dias\n",
    "df['Units_Sold_Rolling7'] = df.groupby(['Product_ID', 'Store_ID'])['Units_Sold'].transform(\n",
    "    lambda x: x.rolling(7, min_periods=1).mean()\n",
    ")\n",
    "df['days_to_stockout'] = df['Inventory_Level'] / (df['Units_Sold_Rolling7'] + 1e-5)\n",
    "\n",
    "# Features temporais\n",
    "df['dayofweek'] = df['Date'].dt.dayofweek\n",
    "df['month'] = df['Date'].dt.month\n",
    "df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)\n",
    "\n",
    "# Tratamento de valores nulos (mais seguro que drop direto)\n",
    "for col in df.select_dtypes(include='number'):\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "for col in df.select_dtypes(include='object'):\n",
    "    df[col] = df[col].fillna(\"desconhecido\")\n",
    "\n",
    "# Tratamento de outliers usando IQR\n",
    "for col in ['Inventory_Level', 'Units_Sold', 'days_to_stockout']:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lim_inf = Q1 - 1.5 * IQR\n",
    "    lim_sup = Q3 + 1.5 * IQR\n",
    "    df = df[(df[col] >= lim_inf) & (df[col] <= lim_sup)]\n",
    "\n",
    "# Encoding das vari√°veis categ√≥ricas\n",
    "categorical_cols = ['Category', 'Region', 'Weather_Condition', 'Holiday_Promotion']\n",
    "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Checar se restou string e tratar\n",
    "cat_cols_remaining = df.select_dtypes(include='object').columns.tolist()\n",
    "if cat_cols_remaining:\n",
    "    df = pd.get_dummies(df, columns=cat_cols_remaining, drop_first=True)\n",
    "\n",
    "print(\"‚úÖ Pr√©-processamento conclu√≠do. Shape final:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7352012",
   "metadata": {},
   "source": [
    "<!-- Etapa 4 -->\n",
    "<div style=\"background:#F7F3FF; border-left:8px solid #FFA726; padding:18px; border-radius:10px; margin-top:24px;\">\n",
    "  <span style=\"font-size:1.2em; color:#4B0055; font-weight:bold;\">4. Escolha dos Modelos</span>\n",
    "  <p style=\"color:#4B0055;\">\n",
    "    Tr√™s modelos escolhidos para treinar em paralelo:<br>\n",
    "    1. <b>Regress√£o Linear</b> ‚Äì baseline, f√°cil de interpretar<br>\n",
    "    2. <b>Random Forest Regressor</b> ‚Äì captura rela√ß√µes n√£o-lineares, fornece import√¢ncia das features<br>\n",
    "    3. <b>XGBoost Regressor</b> ‚Äì boosting eficiente, alta performance em dados tabulares\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff0308e",
   "metadata": {},
   "source": [
    "<div style=\"background:#ffcee5ff; border-left:8px solid #f81e84ff; padding:18px; border-radius:10px; margin-top:24px;\">\n",
    "    <span style=\"font-size:1.2em; color:#4B0055; font-weight:bold;\">Modelos escolhidos, levando em conta interpreta√ß√£o, performance e aplicabilidade:</span>\n",
    "    <ul style=\"margin-top:12px;\">\n",
    "        <li>\n",
    "            <span style=\"color:#f81e84ff; font-weight:bold;\">Regress√£o Linear / Ridge Regression</span><br>\n",
    "            <span style=\"color:#4B0055;\">Boa para prever <b>days_to_stockout</b> como uma vari√°vel cont√≠nua.<br>\n",
    "            F√°cil de explicar para professores/gestores.<br>\n",
    "            Serve como baseline simples.</span>\n",
    "        </li>\n",
    "        <li style=\"margin-top:10px;\">\n",
    "            <span style=\"color:#f81e84ff; font-weight:bold;\">Random Forest Regressor</span><br>\n",
    "            <span style=\"color:#4B0055;\">Modelo de √°rvore baseado em entropia/Gini, mas muito mais robusto.<br>\n",
    "            Capta rela√ß√µes n√£o-lineares entre vari√°veis (ex.: <span><b>sazonalidade</b></span>, promo√ß√µes).<br>\n",
    "            Permite medir a import√¢ncia das features (quais colunas mais influenciam).</span>\n",
    "        </li>\n",
    "        <li style=\"margin-top:10px;\">\n",
    "            <span style=\"color:#f81e84ff; font-weight:bold;\">XGBoost (Extreme Gradient Boosting)</span><br>\n",
    "            <span style=\"color:#4B0055;\">Modelo avan√ßado, muito usado em competi√ß√µes Kaggle.<br>\n",
    "            √ìtimo para dados tabulares com comportamento complexo.<br>\n",
    "            Normalmente supera Random Forest em performance.</span>\n",
    "        </li>\n",
    "        <li style=\"margin-top:10px;\">\n",
    "            <span style=\"color:#f81e84ff; font-weight:bold;\">LightGBM Regressor</span><br>\n",
    "            <span style=\"color:#4B0055;\">Muito r√°pido em datasets grandes.<br>\n",
    "            Funciona bem com features num√©ricas e categ√≥ricas.<br>\n",
    "            Boosting eficiente, frequentemente entrega MAPE menor com menos tempo de treino.</span>\n",
    "        </li>\n",
    "        <li style=\"margin-top:10px;\">\n",
    "            <span style=\"color:#f81e84ff; font-weight:bold;\">CatBoost Regressor</span><br>\n",
    "            <span style=\"color:#4B0055;\">Excelente para dados com muitas vari√°veis categ√≥ricas (ex.: Product_ID, Store_ID).<br>\n",
    "            N√£o exige tanto pr√©-processamento (Label/One-Hot Encoding).<br>\n",
    "            Pode reduzir erros percentuais (MAPE) e √© f√°cil de implementar em produ√ß√£o.</span>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "07941f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos definidos: Linear/Ridge, Random Forest, XGBoost, LightGBM, CatBoost\n"
     ]
    }
   ],
   "source": [
    "print(\"Modelos definidos: Linear/Ridge, Random Forest, XGBoost, LightGBM, CatBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b7cbfe",
   "metadata": {},
   "source": [
    "<!-- Etapa 5 -->\n",
    "<div style=\"background:#F7F3FF; border-left:8px solid #FFA726; padding:18px; border-radius:10px; margin-top:24px;\">\n",
    "  <span style=\"font-size:1.2em; color:#4B0055; font-weight:bold;\">5. Treinamento dos Modelos</span>\n",
    "  <ul style=\"color:#4B0055; margin-top:12px;\">\n",
    "    <li>Usar TimeSeriesSplit ou divis√£o treino/teste</li>\n",
    "    <li>Treinar os modelos em paralelo para cada batch de dados novo</li>\n",
    "    <li>Ajustar par√¢metros iniciais b√°sicos para evitar underfitting (n_estimators, learning_rate, max_depth etc.)</li>\n",
    "  </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadb10a1",
   "metadata": {},
   "source": [
    "<!-- Etapa 5b -->\n",
    "<div style=\"background:#ffe8c6ff; border-left:8px solid #FFA726; padding:18px; border-radius:10px; margin-top:24px;\">\n",
    "  <span style=\"font-size:1.2em; color:#4B0055; font-weight:bold;\">Treinamento Inicial dos Modelos</span>\n",
    "  <p style=\"color:#4B0055;\">\n",
    "    Nesta etapa, treinamos todos os modelos escolhidos com um n√∫mero menor de estimadores/itera√ß√µes para observar rapidamente qual modelo apresenta a <b>menor MAPE</b> e melhor desempenho com informa√ß√µes b√°sicas.\n",
    "    <br><br>\n",
    "    Objetivo: identificar os modelos mais promissores antes de fazer um treinamento completo com mais dados e hiperpar√¢metros ajustados.\n",
    "  </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "487b53a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Treinando LinearRegression...\n",
      "üìä LinearRegression treinado com sucesso!\n",
      "MAPE: 26.06% | Tempo de treino: 0.24s | Tempo de predi√ß√£o: 0.0211s\n",
      "\n",
      "üöÄ Treinando Ridge...\n",
      "üìä Ridge treinado com sucesso!\n",
      "MAPE: 26.06% | Tempo de treino: 0.12s | Tempo de predi√ß√£o: 0.0159s\n",
      "\n",
      "üöÄ Treinando RandomForest...\n",
      "üìä RandomForest treinado com sucesso!\n",
      "MAPE: 24.84% | Tempo de treino: 21.65s | Tempo de predi√ß√£o: 0.2650s\n",
      "\n",
      "üîé Principais features:\n",
      "Inventory_Level    0.657811\n",
      "Demand_Forecast    0.053911\n",
      "Units_Sold         0.043724\n",
      "Units_Ordered      0.036737\n",
      "Price              0.028542\n",
      "dtype: float64\n",
      "\n",
      "üöÄ Treinando XGBoost...\n",
      "üìä XGBoost treinado com sucesso!\n",
      "MAPE: 26.12% | Tempo de treino: 0.76s | Tempo de predi√ß√£o: 0.0396s\n",
      "\n",
      "üîé Principais features:\n",
      "Inventory_Level       0.727011\n",
      "Units_Sold            0.045301\n",
      "Demand_Forecast       0.033116\n",
      "Product_ID_P0005      0.007611\n",
      "Category_Furniture    0.007107\n",
      "dtype: float32\n",
      "\n",
      "üöÄ Treinando LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1547\n",
      "[LightGBM] [Info] Number of data points in the train set: 56560, number of used features: 43\n",
      "[LightGBM] [Info] Start training from score 2.050650\n",
      "üìä LightGBM treinado com sucesso!\n",
      "MAPE: 26.22% | Tempo de treino: 0.74s | Tempo de predi√ß√£o: 0.0300s\n",
      "\n",
      "üîé Principais features:\n",
      "Inventory_Level    647\n",
      "Units_Sold         294\n",
      "Demand_Forecast    264\n",
      "Units_Ordered       63\n",
      "Price               40\n",
      "dtype: int32\n",
      "\n",
      "üöÄ Treinando CatBoost...\n",
      "üìä CatBoost treinado com sucesso!\n",
      "MAPE: 26.89% | Tempo de treino: 1.38s | Tempo de predi√ß√£o: 0.0178s\n",
      "\n",
      "üîé Principais features:\n",
      "Inventory_Level    86.091467\n",
      "Units_Sold          8.438116\n",
      "Demand_Forecast     5.333242\n",
      "month               0.016815\n",
      "Discount            0.015558\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Separar features e target\n",
    "X = df.drop(columns=['days_to_stockout', 'Date', 'Units_Sold_Rolling7'])\n",
    "y = df['days_to_stockout']\n",
    "\n",
    "# Divis√£o treino/teste (80/20 sem embaralhar)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Inicializar modelos com par√¢metros reduzidos para treino r√°pido\n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(alpha=1.0),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=50, learning_rate=0.05, random_state=42, n_jobs=-1),\n",
    "    \"LightGBM\": lgb.LGBMRegressor(n_estimators=50, learning_rate=0.05, random_state=42, n_jobs=-1),\n",
    "    \"CatBoost\": CatBoostRegressor(iterations=50, learning_rate=0.05, verbose=0, random_state=42)\n",
    "}\n",
    "\n",
    "# Fun√ß√£o MAPE customizada para evitar divis√£o por zero\n",
    "def mean_absolute_percentage_error_safe(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / (y_true + 1e-5))) * 100\n",
    "\n",
    "# Treinar e avaliar\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüöÄ Treinando {name}...\")\n",
    "    start_train = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_train = time.time()\n",
    "    \n",
    "    start_pred = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    end_pred = time.time()\n",
    "    \n",
    "    mape = mean_absolute_percentage_error_safe(y_test, y_pred)\n",
    "    results[name] = {'MAPE': mape, \n",
    "                     'Treino_s': end_train - start_train, \n",
    "                     'Predicao_s': end_pred - start_pred}\n",
    "    \n",
    "    print(f\"üìä {name} treinado com sucesso!\")\n",
    "    print(f\"MAPE: {mape:.2f}% | Tempo de treino: {end_train - start_train:.2f}s | Tempo de predi√ß√£o: {end_pred - start_pred:.4f}s\")\n",
    "    \n",
    "    # Import√¢ncia das features, se dispon√≠vel\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        feat_imp = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "        print(\"\\nüîé Principais features:\")\n",
    "        print(feat_imp.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa43c6c8",
   "metadata": {},
   "source": [
    "<!-- Etapa 5c -->\n",
    "<div style=\"background:#ffe8c6ff; border-left:8px solid #FFA726; padding:18px; border-radius:10px; margin-top:24px;\">\n",
    "  <span style=\"font-size:1.2em; color:#4B0055; font-weight:bold;\">Treinamento Avan√ßado dos Modelos Selecionados</span>\n",
    "  <p style=\"color:#4B0055;\">\n",
    "    Com base nos resultados do treinamento inicial, selecionamos os <b>2 melhores modelos</b> (menor MAPE) para um treinamento mais completo usando <b>200 estimadores/itera√ß√µes</b> e todos os dados dispon√≠veis.\n",
    "    <br><br>\n",
    "    Objetivo: avaliar a performance final de cada modelo em condi√ß√µes ideais e decidir qual ser√° o modelo principal para previs√£o de <b>days_to_stockout</b>.\n",
    "  </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "53f2d529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Treinando RandomForest...\n",
      "üìä RandomForest treinado com sucesso!\n",
      "MAPE: 24.67%\n",
      "‚è±Ô∏è Tempo de treino: 261.16 s | Tempo de predi√ß√£o: 1.7065 s\n",
      "\n",
      "üîé Principais features:\n",
      "Inventory_Level       0.657697\n",
      "Demand_Forecast       0.053558\n",
      "Units_Sold            0.044217\n",
      "Units_Ordered         0.036593\n",
      "Competitor_Pricing    0.028606\n",
      "dtype: float64\n",
      "\n",
      "üöÄ Treinando LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1547\n",
      "[LightGBM] [Info] Number of data points in the train set: 56560, number of used features: 43\n",
      "[LightGBM] [Info] Start training from score 2.050650\n",
      "üìä LightGBM treinado com sucesso!\n",
      "MAPE: 24.57%\n",
      "‚è±Ô∏è Tempo de treino: 0.68 s | Tempo de predi√ß√£o: 0.0311 s\n",
      "\n",
      "üîé Principais features:\n",
      "Inventory_Level    1348\n",
      "Units_Sold          697\n",
      "month               593\n",
      "Demand_Forecast     584\n",
      "Units_Ordered       509\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# Modelos selecionados para treino completo\n",
    "best_models = {\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=200, random_state=42),\n",
    "    \"LightGBM\": lgb.LGBMRegressor(n_estimators=200, learning_rate=0.05, random_state=42)\n",
    "}\n",
    "\n",
    "# Fun√ß√£o para calcular MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / (y_true + 1e-5))) * 100  # evita divis√£o por zero\n",
    "\n",
    "# Treinar e avaliar os 2 melhores modelos\n",
    "for name, model in best_models.items():\n",
    "    print(f\"\\nüöÄ Treinando {name}...\")\n",
    "    start_train = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_train = time.time()\n",
    "    \n",
    "    start_pred = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    end_pred = time.time()\n",
    "    \n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    \n",
    "    print(f\"üìä {name} treinado com sucesso!\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")\n",
    "    print(f\"‚è±Ô∏è Tempo de treino: {end_train - start_train:.2f} s | Tempo de predi√ß√£o: {end_pred - start_pred:.4f} s\")\n",
    "    \n",
    "    # Exibir import√¢ncia das features, se dispon√≠vel\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        feat_imp = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "        print(\"\\nüîé Principais features:\")\n",
    "        print(feat_imp.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd630b1",
   "metadata": {},
   "source": [
    "<!-- Etapa 6 -->\n",
    "<div style=\"background:#F7F3FF; border-left:8px solid #FFA726; padding:18px; border-radius:10px; margin-top:24px;\">\n",
    "  <span style=\"font-size:1.2em; color:#4B0055; font-weight:bold;\">6. Avalia√ß√£o do Modelo</span>\n",
    "  <ul style=\"color:#4B0055; margin-top:12px;\">\n",
    "    <li>M√©tricas principais: MAE, MAPE, R¬≤, MSE e RMSE</li>\n",
    "    <li>Comparar resultados entre os modelos treinados</li>\n",
    "    <li>Visualizar predi√ß√£o vs valores reais para identificar erros sistem√°ticos</li>\n",
    "  </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ccca190e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä | LinearRegression - MAE: 0.456 | MAPE: 26.06% | MSE: 0.361 | RMSE: 0.601 | R¬≤: 0.664\n",
      "\n",
      "üìä | Ridge - MAE: 0.456 | MAPE: 26.06% | MSE: 0.361 | RMSE: 0.601 | R¬≤: 0.664\n",
      "\n",
      "üìä | RandomForest - MAE: 0.458 | MAPE: 24.84% | MSE: 0.370 | RMSE: 0.608 | R¬≤: 0.656\n",
      "\n",
      "üìä | XGBoost - MAE: 0.457 | MAPE: 26.12% | MSE: 0.361 | RMSE: 0.600 | R¬≤: 0.664\n",
      "\n",
      "üìä | LightGBM - MAE: 0.457 | MAPE: 26.22% | MSE: 0.361 | RMSE: 0.600 | R¬≤: 0.664\n",
      "\n",
      "üìä | CatBoost - MAE: 0.461 | MAPE: 26.89% | MSE: 0.364 | RMSE: 0.603 | R¬≤: 0.661\n"
     ]
    }
   ],
   "source": [
    "# Avalia√ß√£o completa dos modelos\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {'MAE': mae, 'MAPE': mape, 'MSE': mse, 'RMSE': rmse, 'R2': r2}\n",
    "    \n",
    "    print(f\"\\nüìä | {name} - MAE: {mae:.3f} | MAPE: {mape:.2f}% | MSE: {mse:.3f} | RMSE: {rmse:.3f} | R¬≤: {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25cacb2",
   "metadata": {},
   "source": [
    "<!-- Etapa 7 -->\n",
    "<div style=\"background:#F7F3FF; border-left:8px solid #FFA726; padding:18px; border-radius:10px; margin-top:24px;\">\n",
    "  <span style=\"font-size:1.2em; color:#4B0055; font-weight:bold;\">7. Ajuste de Hiperpar√¢metros</span>\n",
    "  <ul style=\"color:#4B0055; margin-top:12px;\">\n",
    "    <li>Aplicar Grid Search, Random Search ou Otimiza√ß√£o Bayesiana para par√¢metros como: n_estimators, max_depth, learning_rate, min_child_weight</li>\n",
    "    <li>Melhorar performance e evitar overfitting/underfitting</li>\n",
    "  </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed39a2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 20\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# GridSearch para Random Forest\u001b[39;00m\n\u001b[0;32m     12\u001b[0m grid_rf \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     13\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mRandomForestRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m),\n\u001b[0;32m     14\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid_rf,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     19\u001b[0m )\n\u001b[1;32m---> 20\u001b[0m \u001b[43mgrid_rf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m models[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandomForest\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m grid_rf\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Melhor RF:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_rf\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    967\u001b[0m         )\n\u001b[0;32m    968\u001b[0m     )\n\u001b[1;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py:2071\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2065\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2066\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2071\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py:1681\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1680\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1681\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1683\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1684\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py:1799\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[0;32m   1789\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[0;32m   1790\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1794\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[0;32m   1795\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[0;32m   1796\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1797\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[0;32m   1798\u001b[0m     ):\n\u001b[1;32m-> 1799\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1800\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1802\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1803\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[0;32m   1804\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1810\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[0;32m   1811\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # N√£o necess√°rio, mas √∫til para salvar modelos treinados\n",
    "\n",
    "# # Par√¢metros para Random Forest\n",
    "# param_grid_rf = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_depth': [None, 10, 20],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4]\n",
    "# }\n",
    "\n",
    "# # GridSearch para Random Forest\n",
    "# grid_rf = GridSearchCV(\n",
    "#     estimator=RandomForestRegressor(random_state=42),\n",
    "#     param_grid=param_grid_rf,\n",
    "#     scoring='neg_mean_absolute_error',  # MAPE direto n√£o √© suportado no scikit-learn\n",
    "#     cv=3,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=2\n",
    "# )\n",
    "# grid_rf.fit(X_train, y_train)\n",
    "# models['RandomForest'] = grid_rf.best_estimator_\n",
    "# print(\"‚úÖ Melhor RF:\", grid_rf.best_params_)\n",
    "# print(\"MAE do RF otimizado:\", -grid_rf.best_score_)\n",
    "\n",
    "# # Par√¢metros para XGBoost\n",
    "# param_grid_xgb = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_depth': [3, 5, 7],\n",
    "#     'learning_rate': [0.01, 0.05, 0.1],\n",
    "#     'subsample': [0.7, 0.9, 1.0],\n",
    "#     'colsample_bytree': [0.7, 0.9, 1.0]\n",
    "# }\n",
    "\n",
    "# # GridSearch para XGBoost\n",
    "# grid_xgb = GridSearchCV(\n",
    "#     estimator=XGBRegressor(random_state=42),\n",
    "#     param_grid=param_grid_xgb,\n",
    "#     scoring='neg_mean_absolute_error',\n",
    "#     cv=3,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=2\n",
    "# )\n",
    "# grid_xgb.fit(X_train, y_train)\n",
    "# models['XGBoost'] = grid_xgb.best_estimator_\n",
    "# print(\"‚úÖ Melhor XGBoost:\", grid_xgb.best_params_)\n",
    "# print(\"MAE do XGBoost otimizado:\", -grid_xgb.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380002ee",
   "metadata": {},
   "source": [
    "<!-- Etapa 8 -->\n",
    "<div style=\"background:#F7F3FF; border-left:8px solid #FFA726; padding:18px; border-radius:10px; margin-top:24px;\">\n",
    "  <span style=\"font-size:1.2em; color:#4B0055; font-weight:bold;\">8. Valida√ß√£o Cruzada</span>\n",
    "  <ul style=\"color:#4B0055; margin-top:12px;\">\n",
    "    <li>Usar TimeSeriesSplit para avaliar estabilidade do modelo em diferentes per√≠odos</li>\n",
    "    <li>Garante que o modelo generaliza bem para dados futuros</li>\n",
    "  </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fdab7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä LinearRegression - CV m√©dia | MAE: 0.47, MAPE: 26.95%, MSE: 0.379, RMSE: 0.615, R¬≤: 0.65\n",
      "\n",
      "üìä Ridge - CV m√©dia | MAE: 0.47, MAPE: 26.92%, MSE: 0.378, RMSE: 0.615, R¬≤: 0.65\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m X_tr, X_val \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[train_index], X\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[0;32m     13\u001b[0m y_tr, y_val \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[train_index], y\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[1;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[0;32m     18\u001b[0m mae_scores\u001b[38;5;241m.\u001b[39mappend(mean_absolute_error(y_val, y_pred))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:487\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    476\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    479\u001b[0m ]\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py:2071\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2065\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2066\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2071\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py:1681\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1680\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1681\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1683\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1684\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py:1799\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[0;32m   1789\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[0;32m   1790\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1794\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[0;32m   1795\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[0;32m   1796\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1797\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[0;32m   1798\u001b[0m     ):\n\u001b[1;32m-> 1799\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1800\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1802\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1803\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[0;32m   1804\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1810\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[0;32m   1811\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Tamb√©m n√£o √© necess√°rio, mas √∫til para salvar modelos treinados\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "cv_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    mae_scores, mape_scores, mse_scores, rmse_scores, r2_scores = [], [], [], [], []\n",
    "    \n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_tr, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_tr, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "        \n",
    "        mae_scores.append(mean_absolute_error(y_val, y_pred))\n",
    "        mape_scores.append(mean_absolute_percentage_error(y_val, y_pred))\n",
    "        mse_scores.append(mean_squared_error(y_val, y_pred))\n",
    "        rmse_scores.append(np.sqrt(mean_squared_error(y_val, y_pred)))\n",
    "        r2_scores.append(r2_score(y_val, y_pred))\n",
    "    \n",
    "    cv_results[name] = {\n",
    "        'MAE_mean': np.mean(mae_scores),\n",
    "        'MAPE_mean': np.mean(mape_scores),\n",
    "        'MSE_mean': np.mean(mse_scores),\n",
    "        'RMSE_mean': np.mean(rmse_scores),\n",
    "        'R2_mean': np.mean(r2_scores)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüìä {name} - CV m√©dia | MAE: {np.mean(mae_scores):.2f}, MAPE: {np.mean(mape_scores):.2f}%, \"\n",
    "          f\"MSE: {np.mean(mse_scores):.3f}, RMSE: {np.mean(rmse_scores):.3f}, R¬≤: {np.mean(r2_scores):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ac8fba",
   "metadata": {},
   "source": [
    "<!-- Etapa 9 -->\n",
    "<div style=\"background:#F7F3FF; border-left:8px solid #FFA726; padding:18px; border-radius:10px; margin-top:24px;\">\n",
    "  <span style=\"font-size:1.2em; color:#4B0055; font-weight:bold;\">9. Sele√ß√£o do Melhor Modelo</span>\n",
    "  <ul style=\"color:#4B0055; margin-top:12px;\">\n",
    "    <li>Comparar m√©tricas de todos os modelos treinados</li>\n",
    "    <li>Selecionar o modelo com menor MAE/RMSE e boa interpreta√ß√£o</li>\n",
    "    <li>Salvar modelo final para deploy</li>\n",
    "  </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d161fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "melhor_modelo_nome = min(results, key=lambda x: results[x]['MAE'])\n",
    "melhor_modelo = models[melhor_modelo_nome]\n",
    "print(\"Melhor modelo selecionado:\", melhor_modelo_nome)\n",
    "\n",
    "# Salvar modelo\n",
    "joblib.dump(melhor_modelo, f\"best_model_{melhor_modelo_nome}.pkl\")\n",
    "print(\"Modelo salvo com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fafefc8",
   "metadata": {},
   "source": [
    "<!-- Etapa 10 -->\n",
    "<div style=\"background:#F7F3FF; border-left:8px solid #FFA726; padding:18px; border-radius:10px; margin-top:24px;\">\n",
    "  <span style=\"font-size:1.2em; color:#4B0055; font-weight:bold;\">10. Deploy / Implementa√ß√£o</span>\n",
    "  <ul style=\"color:#4B0055; margin-top:12px;\">\n",
    "    <li>Integrar modelo ao app Fluxar para gerar alertas autom√°ticos de stockout</li>\n",
    "    <li>Pode ser via API, painel web ou notifica√ß√£o push</li>\n",
    "  </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a78c0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N√£o fazemos esse passo no notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f4933d",
   "metadata": {},
   "source": [
    "<!-- Etapa 11 -->\n",
    "<div style=\"background:#F7F3FF; border-left:8px solid #FFA726; padding:18px; border-radius:10px; margin-top:24px; margin-bottom:24px;\">\n",
    "  <span style=\"font-size:1.2em; color:#4B0055; font-weight:bold;\">11. Monitoramento e Manuten√ß√£o</span>\n",
    "  <ul style=\"color:#4B0055; margin-top:12px;\">\n",
    "    <li>Acompanhar performance do modelo ao longo do tempo</li>\n",
    "    <li>Re-treinar com novos dados ou ajustar hiperpar√¢metros em caso de concept drift</li>\n",
    "  </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5670ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N√£o fazemos esse passo no notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
